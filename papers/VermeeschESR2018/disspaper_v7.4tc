\expandafter\ifx\csname doTocEntry\endcsname\relax \expandafter\endinput\fi
\doTocEntry\tocsection{1}{\csname a:TocLink\endcsname{1}{x1-10001}{QQ2-1-1}{Introduction}}{4}\relax 
\doTocEntry\toclof{1}{\csname a:TocLink\endcsname{1}{x1-10081}{}{\ignorespaces $A-C$: Probability Density Functions (PDFs) of three synthetic age distributions; $D-F$: PDFs of the dates obtained from $A-C$ assuming 2\nobreakspace  {}Ma absolute measurement uncertainties; $G-I$: PDFs of the dates obtained from $A-C$ assuming \SI {2}{\percent } relative measurement uncertainties.}}{figure}\relax 
\doTocEntry\tocsection{2}{\csname a:TocLink\endcsname{1}{x1-20002}{QQ2-1-3}{chi-square}}{8}\relax 
\doTocEntry\toclot{1}{\csname a:TocLink\endcsname{1}{x1-20021}{}{\ignorespaces Chi-square statistics for the comparison of (i) samples $a$, $b$, $c$ and $d$, which contain $\sim $20 dates each; and (ii) samples $e$, $f$, $g$ and $h$, which contain $\sim $200 dates each, collected from populations $D$ (samples $a$, $b$, $e$ and $f$), $E$ (samples $c$ and $g$) and $F$ (samples $d$ and $h$).}}{table}\relax 
\doTocEntry\tocsubsection{2.1}{\csname a:TocLink\endcsname{1}{x1-30002.1}{QQ2-1-5}{hypothesis testing}}{12}\relax 
\doTocEntry\tocsubsection{2.2}{\csname a:TocLink\endcsname{1}{x1-40002.2}{QQ2-1-6}{effect size}}{13}\relax 
\doTocEntry\toclot{2}{\csname a:TocLink\endcsname{1}{x1-40022}{}{\ignorespaces Chi-square population effect sizes ($\epsilon $) of populations $D$--$F$.}}{table}\relax 
\doTocEntry\toclof{2}{\csname a:TocLink\endcsname{1}{x1-40042}{}{\ignorespaces The non-central chi-square distribution for comparison of two samples collected from populations $D$ and $E$ using sample sizes of 20 and 200 dates; the vertical line marks the 95\% cutoff for the null hypothesis ($H_\circ $) that both samples were derived from the same distribution. Small samples are more likely to yield low $X_{stat}^2$-values and fail to reject $H_\circ $, incurring a Type-I error. For the 20-grain dataset, this occurs 78\% of the time.}}{figure}\relax 
\doTocEntry\tocsubsection{2.3}{\csname a:TocLink\endcsname{1}{x1-50002.3}{QQ2-1-9}{The trouble with p-values}}{19}\relax 
\doTocEntry\tocsection{3}{\csname a:TocLink\endcsname{1}{x1-60003}{QQ2-1-10}{Non-parametric statistics}}{20}\relax 
\doTocEntry\toclof{3}{\csname a:TocLink\endcsname{1}{x1-60023}{}{\ignorespaces The expected distribution (based on 1000 simulations) of the Kolmogorov-Smirnov (KS) statistic comparing one sample collected from population $E$ with another sample from the same population ($H_\circ $, blue distributions), or with a sample from population $F$ ($H_a$, red distributions), for sample sizes of $n=20$ (histograms) and $n=200$ dates per sample (continuous curves).}}{figure}\relax 
\doTocEntry\toclof{4}{\csname a:TocLink\endcsname{1}{x1-60064}{}{\ignorespaces The Kolmogorov-Smirnov (red) and Kuiper (blue) statistics are equally sensitive to the difference between sample distributions $x$ and $y$, which are laterally offset with respect to each other. The Kuiper statistic is more sensitive than the KS-statistic to the difference between sample distributions $x$ and $z$, which lies in their tails.}}{figure}\relax 
\doTocEntry\tocsection{4}{\csname a:TocLink\endcsname{1}{x1-70004}{QQ2-1-13}{Ad-hoc dissimilarity measures}}{28}\relax 
\doTocEntry\tocsubsection{4.1}{\csname a:TocLink\endcsname{1}{x1-80004.1}{QQ2-1-14}{likeness and cross-correlation}}{28}\relax 
\doTocEntry\toclof{5}{\csname a:TocLink\endcsname{1}{x1-80045}{}{\ignorespaces Two samples $j$ and $k$ were drawn from population $A$ with 0.05\nobreakspace  {}Ma analytical uncertainties (1$\sigma $). Left: due to the high precision, the Probability Density Plots (PDPs) of the two samples consist of a number of spikes resulting in an extremely low value of 0.21\% for \citet  {satkoski2013}'s likeness parameter. Right: evaluating the two PDPs at 200 equally spaced points and plotting the corresponding values against each other yields a cross-correlation coefficient \citep  {saylor2013} of only $7.7 \times 10^{-4}$. These results demonstrate that neither likeness nor cross-correlation are viable dissimilarity measures.}}{figure}\relax 
\doTocEntry\toclof{6}{\csname a:TocLink\endcsname{1}{x1-80056}{}{\ignorespaces (i) Two piecewise uniform populations $J$ (red) and $K$ (blue); (ii) two samples $l$ (red) and $m$ (blue), drawn from $J$ and $K$, respectively, and affected by 10\nobreakspace  {}Ma analytical uncertainties (1$\sigma $); (iii) the PDPs of the two samples are smoothed versions of the distributions of the dates shown in the previous panel; this results in a partial overlap of the two curves, causing (iv) \citet  {saylor2013}'s cross-correlation coefficient to be significantly greater than zero. This is simply an artifact of the use of PDPs and says nothing about the data.}}{figure}\relax 
\doTocEntry\tocsubsection{4.2}{\csname a:TocLink\endcsname{1}{x1-90004.2}{QQ2-1-17}{Sircombe-Hazelton}}{35}\relax 
\doTocEntry\toclof{7}{\csname a:TocLink\endcsname{1}{x1-90057}{}{\ignorespaces (i) the Kernel Density Estimate (KDE) of sample $m$, which was drawn from population $K$ with $\sigma $=10\nobreakspace  {}Ma analytical uncertainties; (ii) the KDE of sample $o$, which was also drawn from population $K$, but with $\sigma $=1\nobreakspace  {}Ma analytical uncertainties; (iii) the PDP of sample $m$, which is double smoothed with respect to $K$; (iv) the PDP of sample $o$, which is smoothed less than that of $m$ due to the smaller analytical uncertainties of $o$ compared to $m$; (v) the Kernel Functional Estimate (KFE) of sample $m$ with $c_1^2=250$ in Equation\nobreakspace  {}12\hbox {}; (vi) the KFE of sample $o$ using the same value of $c_1^2$, which smooths this precise dataset more than sample $m$.}}{figure}\relax 
\doTocEntry\tocsection{5}{\csname a:TocLink\endcsname{1}{x1-100005}{QQ2-1-19}{Multi-sample comparison}}{39}\relax 
\doTocEntry\toclot{3}{\csname a:TocLink\endcsname{1}{x1-100013}{}{\ignorespaces Table of Kolmogorov-Smirnov p-values comparing 10 random samples of 100 ages from population $A$ with each other. Three of these values fall below the $\alpha = 0.05$ cutoff that is typically used for a statistical hypothesis test. In other words, three Type-I errors have been committed in this multiple comparison exercise.}}{table}\relax 
\doTocEntry\tocsection{6}{\csname a:TocLink\endcsname{1}{x1-110006}{QQ2-1-21}{Conclusions}}{44}\relax 
\doTocEntry\toclof{8}{\csname a:TocLink\endcsname{1}{x1-110018}{}{\ignorespaces Kolmogorov-Smirnov-based Multidimensional Scaling (MDS) configuration of samples $a - h$ and $q - w$, whose sampling distributions are shown in Figure\nobreakspace  {}1\hbox {}. black lines connect samples drawn from identical detrital populations. Despite an order of magnitude difference in sample size between samples $a - e$, $q - s$ (20 grains each, blue) and $d - h$, $u - w$ (200 grains each, red), the MDS configuration correctly groups the samples according to provenance. This illustrates that the sample-size dependence of the KS-dissimilarity shown in Figure\nobreakspace  {}3\hbox {} does not pose a major problem for MDS analysis. The x- and y-scale are normalised to the sum of the squared Euclidean distances within the MDS configuration. }}{figure}\relax 
\doTocEntry\toclikesection{}{\csname a:TocLink\endcsname{1}{x1-120006}{QQ2-1-23}{Appendix: power analysis and confidence intervals}}{48}\relax 
\doTocEntry\toclof{9}{\csname a:TocLink\endcsname{1}{x1-120039}{}{\ignorespaces The vertical line marks the observed $X_{stat}^2$-value for comparison between samples $a$ and $d$ (Table\nobreakspace  {}1\hbox {}.i); the two non-central chi-square distributions mark a 95\% confidence interval [0.54,1.16] for the population effect size $\epsilon $. }}{figure}\relax 
\doTocEntry\toclikesection{}{\csname a:TocLink\endcsname{1}{x1-130006}{QQ2-1-25}{Acknowledgments}}{52}\relax 
\doTocEntry\toclikesection{}{\csname a:TocLink\endcsname{1}{x1-140006}{QQ2-1-26}{References}}{52}\relax 
